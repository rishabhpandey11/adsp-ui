<div class="m-5 overflow-hidden space-y-4 ">
    <div class="text-3xl font-sans font-semibold">
        <h1>Chapter 3 : SNR and Non-uniform Quantization</h1>
    </div>



    <!-- Section 1: Learning Objectives -->
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined" style="background-color: #F4EEFF;">
            <mat-card-header>
                <mat-card-title class="text-blue-600"> Learning Objectives</mat-card-title>
            </mat-card-header>
            <br />
            <mat-card-content class="text-lg">
                <p>After completing this module, learners will be able to:</p>
                <ul class="space-y-2">
                    <li>Understand the Motivation for Non-Uniform Quantization.</li>

                    <li>
                        Define SNR and derive it for non-uniform quantizer.
                    </li>
                    <li>
                        Analyze SNR for Non-Uniform PDFs.
                    </li>
                    <li>
                        Explain how non-full-range signals reduce SNR and quantify the penalty.
                    </li>
                    <li>
                        Verify theory with a short Monte-Carlo Python experiment.
                    </li>
                </ul>
            </mat-card-content>
        </mat-card>
    </div>



    <!-- Section 2.1: Theory Summary -->
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">
            <mat-card-header>
                <mat-card-title class="text-blue-600">3.1. SNR with Sinusoidal Signals </mat-card-title>
            </mat-card-header>
            <br />
            <mat-card-content class="text-lg">
                <p class="text-lg ">
                    What is our SNR if we have a sinusoidal signal? What is its PDF?
                    Basically, it is its normalized histogram such that its integral becomes 1 to obtain
                    a probability distribution.
                </p>

                <p class="text-lg mt-3">
                    If we look at the signal and try to see how probable it is for the signal to be in a
                    certain small interval on the y-axis, we see that the signal stays longest around +1
                    and ‚àí1 because there the signal slowly turns around. Hence, we would expect a PDF
                    which has peaks at +1 and ‚àí1.
                </p>

                <p class="text-lg mt-3">
                    If you calculate the PDF of a sine wave x = sin(t), with t being continuous and with
                    a range larger than 2œÄ, then the result is (see Figure 3.1):
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
p(x) = \frac{1}{\pi\sqrt{1 - x^2}}
 $$"></p>

                <p class="text-lg mt-3">
                    This results from the derivative of the inverse sine function (arcsin). This derivation can be
                    found in various sources, such as Wikipedia [9] and standard digital signal processing textbooks
                    [10], [11]. For our probability density function, we need to know how fast a signal x passes
                    through a given bin in x. This is what we obtain if we compute the inverse function
                    x = f-inverse(y) and then its derivative df-inverse(y)/dy.
                </p>

                <p class="text-lg mt-3">
                    Here we can see that p(x) indeed becomes infinite at x = plus or minus 1. We could now use the same
                    approach as before to obtain the expectation of the power by multiplying it with x squared and
                    integrating it. But this seems to be somewhat tedious. However, since we now have a deterministic
                    signal, we can also try an alternative solution since the sine function is not a probabilistic
                    function but a deterministic function. We can simply directly compute the power of our sine signal
                    over time t, and then take the average over at least one period of the sine function.
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
E[x^2] = \frac{1}{2\pi} \int_0^{2\pi} \sin^2(t) \, dt = \frac{1}{2\pi} \int_0^{2\pi} \frac{1 - \cos(2t)}{2} \, dt
 $$"></p>


                <p class="text-lg mt-4">
                    The cosine integrated over complete periods becomes 0, hence we get
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ E[x^2] = \frac{1}{2\pi} \int_0^{2\pi} \frac{1}{2} \, dt = \frac{1}{2\pi} \cdot \frac{\pi}{2} = \frac{1}{2}

 $$"></p>
                <p class="text-lg mt-4">
                    What do we get for a sinusoid with a different amplitude say $A \cdot \sin(t)$? The expected power
                    is
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ E[x^2] = \frac{A^2}{8}

 $$"></p>


                <p class="text-lg mt-4">
                    So this leads to an SNR of
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ \text{SNR} = \frac{A^2}{8\Delta^2/12} = \frac{3A^2}{2\Delta^2}

 $$"></p>


                <p class="text-lg mt-4">
                    Now assume again we have an A/D converter with N bits and the sinusoid is at full range for this
                    converter. Then $A = 2^N \cdot \Delta$. We can plug in this result into the above equation and get
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ \text{SNR} = \frac{3 \cdot 2^{2N} \cdot \Delta^2}{2\Delta^2} = 1.5 \cdot 2^{2N}

 $$"></p>

                <p class="text-lg mt-4">
                    In dB this will now be
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$  \text{SNR}_{\text{dB}} = 10 \cdot \log_{10}(\text{SNR}) = 10 \cdot \log_{10}(1.5) + N \cdot 20 \cdot \log_{10}(2) = 1.76 \text{ dB} + N \cdot 6.02 \text{ dB}

 $$"></p>


                <p class="text-lg mt-4">
                    Here we can see now that using a sinusoidal signal instead of a uniformly distributed signal gives
                    us a
                    boost of 1.76 dB in SNR. This is because it is more likely to have larger values! We see that our
                    rule
                    of 6dB more SNR for each bit still holds!
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap3/fig3.11.png" class="w-180 h-110 ">
                </div>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap3/fig3.21.png" class="w-180 h-110 ">
                </div>

            </mat-card-content>
        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">
            <mat-card-header>
                <mat-card-title class="text-blue-600">3.2 Companding </mat-card-title>
            </mat-card-header>
            <mat-card-content class="text-lg">


                <p class="text-lg mt-4">
                    This is a scheme to make the SNR less dependent on the signal size. This is a synonym for
                    compression and expanding. Uniform quantization can be seen as a quantization value which is
                    constant on the absolute scale. Non-uniform quantization using companding can be seen as having step
                    sizes which stay constant relative to the amplitude; their step size grows with the amplitude. We
                    obtain this non-uniform quantization by first applying a non-linear function to the signal (to boost
                    small values) and then apply a uniform quantizer. On the decoding side, we first apply the reverse
                    quantizer and then the inverse non-linear function (the expansion we reduce small values again to
                    restore their original size).
                </p>

                <p class="text-lg mt-4">
                    The range of (index) values is compressed; smaller values become larger, large values don‚Äôt grow as
                    fast. The following functions are standardized as "u-Law" and "A-Law" (see Figure 3.3):
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap3/fig3.31.png" class="w-180 h-110 ">
                </div>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y = \text{sign}(x) \cdot \frac{\ln(1 + 255 \cdot \frac{|x|}{A})}{\ln(1 + 255)} \tag{3.1}
 $$"></p>


                <p class="text-lg mt-4">
                    In the example of 8-bit mu-law PCM, the quantization index is then (for a Mid-Tread quantizer
                    following this compression function):
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\text{index} = \text{round}\left(\frac{y}{\Delta}\right)
 $$"></p>


                <p class="text-lg mt-4">
                    Here y has the range of -1 to +1. Hence the quantization step size for 8 bits is </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\Delta = \frac{1 - (-1)}{2^8} = \frac{2}{256} = \frac{1}{128}
 $$"></p>



                <p class="text-lg mt-4">
                    The index is then encoded as an 8-bit codeword.

                    In the decoder, we compute the de-quantized $y$ from a Mid-Tread de-quantizer including its sign
                    from the index
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y_{\text{rek}} = \text{index} \cdot \Delta
                $$"></p>



                <p class="text-lg mt-4">
                    and we compute the inverse compression function, the ‚Äúexpanding‚Äù function (hence the name
                    ‚Äúcompanding‚Äù, see Figure 3.3):
                </p>


                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap3/fig3.41.png" class="w-180 h-30 ">
                </div>

                <p class="text-lg mt-4">
                    We obtain the inverse through the following steps
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y \cdot \ln(256)= \ln(1 + 255 \cdot \frac{|x|}{A})                $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
e^{\ln(256) \cdot y} = 1 + 255 \cdot \frac{|x|}{A}                $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
256^y - 1 = 255 \cdot \frac{|x|}{A}                $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 

y = \frac{\ln(1 + 255 \cdot \frac{|x|}{A})}{\ln(1 + 255)}                 $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
x = \text{sign}(y) \cdot \frac{A}{255} \cdot (256^y - 1)                $$"></p>

                <p class="text-lg mt-4">
                    (In the decoder, we replace y by y_rek and x by x_rek).
                    This x is now our de-quantized value or signal.
                    Observe that with this companding the effective quantisation step size
                    remains approximately constant relative to the signal amplitude.
                    Large signal components have large effective step sizes and hence larger
                    quantisation errors; small signals have smaller effective quantisation
                    step sizes and hence smaller quantisation errors.
                    In this way, we get a more or less constant SNR over a wide range of
                    signal amplitudes [12].
                </p>

                <p class="text-lg mt-4">
                    <strong>Important point to remember:</strong>
                    This approach is identical to having non-uniform quantization step sizes;
                    smaller step sizes at smaller signal values and larger step sizes at larger
                    signal values. The compression and expanding of the signal makes the uniform
                    step sizes ‚Äúlook‚Äù relatively smaller to the signal, since it has more
                    quantization steps to cover.
                </p>

                <p class="text-lg mt-4">
                    And this has the same effect as a smaller signal with smaller quantization
                    steps.
                </p>

            </mat-card-content>

        </mat-card>
    </div>




    <!-- Section 2.2: Examples of Uniform PDFs -->
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">
            <mat-card-header>
                <mat-card-title style="color: blue;">3.3 Python Example of Mu-Law Quantizer</mat-card-title>
            </mat-card-header>
            <br />
            <mat-card-content class="text-lg">
                <p class="text-lg mt-4">

                    First, listen to the uniform mid-tread quantizer using our Python script
                    and make sure the part for the mid-tread quantizer is un-commented:
                </p>

                <p class="text-lg mt-4">

                    <code>python pyrecplay_quantizationblock.py</code>
                </p>

                <p class="text-lg mt-4">

                    Observe that the voice disappears if rounded to zero when the speaker is
                    at some distance from the microphone. Now use mu-law quantization with:
                </p>

                <p class="text-lg mt-4">

                    <code>python pyrecplay_mulawquantizationblock.py</code>
                </p>

                <p class="text-lg mt-4">

                    <strong>Observe:</strong>
                    At the distance at which the speech disappeared in the uniform case,
                    the speech is now present. Here the smaller quantisation steps help with
                    the smaller amplitudes of the speech signal. At closer distances where
                    the signal amplitudes are bigger, there is not much difference.
                </p>

                <p class="text-lg mt-4">

                    The programs use 16-bit audio samples from the sound card. One bit is used
                    for the sign, leaving 15 bits for the magnitude. This results in a
                    normalization factor of 32768 to map the values into the range required
                    by the formula from 0 to 1. The mu-law program simulates 4-bit quantization
                    with 16 quantization intervals [11].
                </p>



            </mat-card-content>
        </mat-card>
    </div>






    <!-- Test section  -->
    <div class="h-6"></div>

    <div class="flex flex-col items-center p-3 gap-6">
        <h2 class="text-2xl font-sans font-semibold mb-4">üß† Test Your Knowledge</h2>

        <div *ngFor="let q of questions" class="w-full md:w-2/3">
            <mat-card class="mat-elevation-z6 p-6 font-sans">
                <mat-card-title>{{ q.text }}</mat-card-title>
                <br>

                <mat-card-content>
                    <mat-radio-group [(ngModel)]="q.selectedAnswer" [disabled]="q.isSubmitted">
                        <div *ngFor="let option of q.options" class="mb-2">
                            <mat-radio-button [value]="option">{{ option }}</mat-radio-button>
                        </div>
                    </mat-radio-group>

                    <div class="mt-4 flex gap-3">
                        <button matFab extended (click)="submitAnswer(q)"
                            [disabled]="!q.selectedAnswer || q.isSubmitted">
                            Submit
                        </button>

                        <button matFab extended style="background-color:black ; color: aliceblue;" *ngIf="q.isSubmitted"
                            (click)="tryAgain(q)">
                            Try Again
                        </button>
                    </div>

                    <div class="mt-4">
                        <p *ngIf="q.isSubmitted && q.selectedAnswer === q.correctAnswer"
                            class="text-green-600 font-semibold font-sans">
                            ‚úÖ Correct!
                        </p>
                        <p *ngIf="q.isSubmitted && q.selectedAnswer !== q.correctAnswer"
                            class="text-red-600 font-semibold font-sans">
                            ‚ùå Incorrect. Correct answer: <strong>{{ q.correctAnswer }}</strong>.
                        </p>
                    </div>
                </mat-card-content>
            </mat-card>
        </div>
    </div>





</div>