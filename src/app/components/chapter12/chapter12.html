<div class="m-5 overflow-hidden space-y-4 ">
    <div class=" text-3xl font-sans font-semibold">
        <h1>Chapter 12 : Wiener and Matched Filter, Prediction</h1>
    </div>
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined" style="background-color: #6AECE1;">
            <mat-card-header>
                <mat-card-title style="color: black;"> Learning Objectives</mat-card-title>
            </mat-card-header>
            <br>
            <mat-card-content class="text-lg">


                <ul class="space-y-4 m-4 list-disc ">
                    <li>Understand the purpose and design of Wiener filters for signal reconstruction and noise
                        reduction.</li>
                    <li>Learn matched filters for maximizing SNR in signal detection applications.</li>
                    <li>Implement prediction filters for estimating future signal samples from past data.</li>
                    <li>Apply prediction with quantization for practical coding systems.</li>
                </ul>
            </mat-card-content>

        </mat-card>


    </div>



    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">
            <mat-card-header>
                <mat-card-title style="color: blue;">Introduction</mat-card-title>
            </mat-card-header>
   
            <mat-card-content class="text-lg">
                <p class="text-lg mt-2">
                    Wiener filter  (signal fidelity, the reconstruction is
                    close to the original, for instance for de-noising an image or audio signal, where
                    the audio signal does not need to be deterministic)
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
     h_W(n) :y(n) * h_W(n) \to x(n)
 $$"></p>

                <p class="text-lg mt-3">
                    Matched filter (no signal fidelity, just high
                    SNR for detection, in communication applications, where you would like to detect a
                    0 or 1, or any given known signal, usually a deterministic signal; object recognition
                    in images, face recognition).
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
h_M(n):y(n) * h_M(n) \to x(n) * h_M(n)
 $$"></p>
                <p class="text-lg mt-2">
                    The goal here is an approximation of the original signal x(n) in the least mean squared
                    sense, meaning we would like to minimize the mean quadratic error between the filtered
                    and the original signal, because it is mathematically convenient.
                    We have a filter system with Wiener Filter hW (n)
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y(n) * h_w(n) \to x(n)
 $$"></p>




                <p class="text-lg mt-2">
                    meaning we filter our distorted signal y(n) with our still unknown filter hW (n).
                    The convolution of hW (n)(with filter length L) with y(n) is
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\sum_{m=0}^{L-1} y(n-m) \cdot h_W(m) \to x(n)
 $$"></p>


                <p class="text-lg mt-3">
                    A well known mathematical approach to obtain the minimum of a mean squared error
                    in a matrix framework is the so-called Moore-Penrose Pseudo Inverse [29]. To be able
                    to apply it we can reformulate our convolution equation as a matrix multiplication.
                    Let‚Äôs define 2 vectors. The first is a vector of the the past L samples of our noisy
                    signal y, with the past on the right (flipped), up to the present sample at time n, (bold
                    face font to indicate that it it a vector)
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{y}(n) = [y(n), y(n-1), ..., y(n-L+1)]
 $$"></p>



                <p class="text-lg mt-3">
                    The next vector contains the impulse response,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}_W = [h_W(0), h_W(1), ..., h_W(L-1)]
 $$"></p>

                <p class="text-lg mt-3">
                    Using those 2 vectors, we can rewrite our convolution equation above as a vector multiplication,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
x(n) = {y}(n) \cdot {h}_W^T
 $$"></p>

                <p class="text-lg mt-2">
                    Observe that hW has no time index because it already contains all the samples of the
                    time-reversed impulse response, and is constant.
                    We can now also put the output signal x(n) into the row vector,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{x} = [x(0), x(1), ...]
 $$"></p>


                <p class="text-lg mt-3">
                    To obtain this vector, we simply assemble all the row vectors of our noisy signal y(n)
                    into a matrix A,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A} = \begin{bmatrix} {y}(0) \\ {y}(1) \\ \vdots \end{bmatrix}
 $$"></p>




                <p class="text-lg mt-3">
                    With this matrix, we obtain the result of our convolution at all time steps n to
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A} \cdot {h}_W^T \to {x}^T
 $$"></p>



                <p class="text-lg mt-3">
                    this is just another way of writing our convolution.
                    For the example of a filter length of hW of L=2 hence we get,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\begin{bmatrix} y(1) & y(0) \\ y(2) & y(1) \\ y(3) & y(2) \\ \vdots & \vdots \end{bmatrix} \cdot \begin{bmatrix} h_W(0) \\ h_W(1) \end{bmatrix} \to \begin{bmatrix} x(0) \\ x(1) \\ x(2) \\ \vdots \end{bmatrix}
 $$"></p>



                <p class="text-center mt-3 text-lg ">
                    This is now the matrix multiplication formulation of our convolution.
                    We can now obtain the minimum mean squared error solution of this matrix multiplication using the
                    Moore-Penrose pseudo inverse.
                    This pseudo-inverse finds the column vector h
                    T which minimizes the distance to a
                    given x with the matrix A (which contains our signal y to be filtered):
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A} \cdot {h}_W^T \to {x}^T
 $$"></p>

                <p class="text-center mt-3 text-lg ">
                    Matrix A and vector x are known (this is done in a ‚Äútrainings‚Äù-phase to obtain the
                    Wiener filter coefficients hW , from noisy signals in matrix A and the known clean

                    signals in vector x). Vector hW is unknown so far. After the trainings-phase the filter
                    can also be applied to similar signals.
                    This problem can be solved exactly if the matrix A is square and invertible. Just
                    multiplying the equation with A‚àí1
                    from the left would give us the solution
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}_W^T = {A}^{-1} \cdot {x}^T
 $$"></p>


                <p class="text-lg mt-3">
                    This cannot be done, if A is non-square, for instance if it has many more rows than
                    columns. In this case we don‚Äôt have an exact solution, but many solutions that come
                    close to x . We would like to obtain the solution which comes closest to x in a mean
                    squared error distance sense (also called Euclidean Distance).
                    This solution is derived using the pseudo-inverse. First we multiply both sides by AT,
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A}^T \cdot {A} \cdot {h}_W^T = {A}^T \cdot {x}^T
 $$"></p>




                <p class="text-center mt-3 text-lg ">
                    Here, AT
                    ¬∑ A is now a square matrix, and the formulation is no longer over-determined,
                    hence we can replace the right arrow by an equal sign. The square matrix usually
                    invertible, such that we obtain our solution
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}_W^T = ({A}^T \cdot {A})^{-1} {A}^T \cdot {x}^T
 $$"></p>

                <p class="text-lg mt-3">
                    This hW is now the solution we where looking for. This solution has the minimum mean
                    squared distance to the un-noisy version of all solutions.
                </p>
                <h1 class="mt-4">üß™ Interactive Python Example</h1>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

ipython --pylab
from sound import *
from scipy import signal as sp
x, fs = wavread(‚Äôfspeech.wav‚Äô)
#make x a matrix and transpose it into a column:
x=matrix(x).T
sound(array(x), fs)
#additive zero mean white noise (for -2**15 < x < +2**15):
y=x+0.1*(random.random(shape(x))-0.5)*2**15
sound(array(y), fs)
#we assume L=10 coefficients for our Wiener filter.
#10 to 12 is a good number for speech signals.
A = matrix(zeros((100000, 10)))
for m in range(100000):
A[m,:] = flipud(y[m+arange(10)]).T
#Our matrix has 100000 rows and 10 colums:
print A.shape

# (100000, 10)

#Compute Wiener Filter:

#Trick: allow filter delay of 5 samples
#to get better working denoising.
#This corresponds to the center of our Wiener filter.
#The desired signal hence is x[5:100005].
#Observe: Since we have the matrix type, operator

# "*" is matrix multiplication!

h=inv(A.T*A)*A.T*x[5:100005]
plot(h)
xlabel(‚ÄôSample‚Äô)
ylabel(‚Äôvalue‚Äô)
title(‚ÄôImpulse Response of Wiener Filter‚Äô)

</pre>


                <p class="text-lg mt-3">
                    The resulting plot can be seen in Fig. (12.13). Observe that for this impulse response we see a
                    delay of 4 samples (the peak is at sample number 4).
                    Its frequency response is obtained with
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.1.png" class="w-180 h-110 ">


                </div>


                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

from freqz import *
freqz(flipud(h))

</pre>
                <p class="text-lg mt-3">
                    The resulting plot can be seen in Fig. (12.14). Here we can see that the resulting filter
                    has a somewhat low pass characteristic, because our speech signal has energy mostly at
                    low frequencies. At high frequencies we have mostly noise, hence it makes sense to
                    have more attenuation there! This attenuation curve of this Wiener filter also has some
                    similarity to the speech spectrum. If we compare it with the spectrum of our white noise,
                    then we see that at low frequencies the speech is dominating, and at high frequencies
                    noise is dominating. hence we need to remove or attenuate that latter, noisy, part of the
                    spectrum.
                    We can plot the spectra of the speech and the noise together with (this time with the
                    freqz from the signal processing library, without the build in plotting):
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.2.png" class="w-180 h-130 ">


                </div>
                <p class="text-center mt-3 text-lg">
                    has a somewhat low pass characteristic, because our speech signal has energy mostly at
                    low frequencies. At high frequencies we have mostly noise, hence it makes sense to
                    have more attenuation there! This attenuation curve of this Wiener filter also has some
                    similarity to the speech spectrum. If we compare it with the spectrum of our white noise,
                    then we see that at low frequencies the speech is dominating, and at high frequencies
                    noise is dominating. hence we need to remove or attenuate that latter, noisy, part of the
                    spectrum.
                    We can plot the spectra of the speech and the noise together with (this time with the
                    freqz from the signal processing library, without the build in plotting):
                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

w,Hspeech=sp.freqz(x);
w,Hnoise=sp.freqz(0.1*(random.random(shape(x))-0.5)*2**15);
w,Hw=sp.freqz(h);
plot(w,20*log10(abs(Hspeech)));
hold
plot(w,20*log10(abs(Hnoise)),‚Äôr‚Äô);
#plot and shift the filter into the vicinity of the signal:
plot(w,20*log10(abs(Hw))+100,‚Äôg‚Äô);
xlabel(‚ÄôNormalized Frequency‚Äô)
ylabel(‚ÄôMagnitude (dB)‚Äô)
legend((‚ÄôSpeech‚Äô, ‚ÄôWhite Noise‚Äô, ‚ÄôWiener Filter‚Äô))
title(‚ÄôMagnitude Spectrum‚Äô)

</pre>
                <p class="text-lg mt-3">
                    The resulting plot can be seen in Fig. (12.15). Here we see that speech dominates the spectrum only
                    at low and middle frequencies, noise at the other frequencies, hence
                    it makes sense to suppress those noisy frequencies.
                    Now we can filter it. For ‚Äúlfilter‚Äù function argument we need to convert the matrix
                    type into a 1 dimensional array type:
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.3.png" class="w-180 h-110 ">

                    <h1 class="text-wrap">

                    </h1>
                </div>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

xw = sp.lfilter(array(h.T)[0],[1],array(y.T)[0])
#and listen and compare it:
original:
sound(array(x), fs)
noisy:
sound(array(y),fs)
Wiener Filtered:
sound(xw, fs)

</pre>

                <p class="text-lg mt-3">
                    We can hear that the signal now sounds more ‚Äúmuffled‚Äù, the higher frequencies are
                    indeed attenuated, which reduces the influence of the noise. But it is still a question if it

                    actually ‚Äúsounds‚Äù better to the human ear, because the ear is not looking for the mean
                    squared error solution.
                    This Wiener filter could now also be applied to other speech signals, with similar
                    frequency characteristics for signal and noise.
                    Let‚Äôs compare the mean (squared) quadratic error (mse), to see if it is indeed reduced,
                    and by how much. For the noisy signal it is
                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

print shape(x)
#(207612, 1)
#Compute the quadratic error for the first 200000 samples:
sum(power(y[:200000]-x[:200000],2))/200000
# 895724.70095581945

For the Wiener filtered signal it is 
(taking into account 4 samples delay from our 
filtersum(power(xw[4:200004]-x[:200000].T,2))/200000
# 373727.8735729566

We can see that the mean quadratic error is indeed
 less than half as much as for the noisLet‚Äôs take a look at the 
 matrix $\boldsubformula A^T\cdot \boldsubformula A$ which we usA.T*A
out:
matrix([[ 1.08192901e+12, 9.19784413e+11, 8.64233389e+11,
9.02427205e+11, 8.96487813e+11, 8.52517530e+11,
8.28117032e+11, 7.98498157e+11, 7.63978129e+11,
7.41600697e+11],
[ 9.19784413e+11, 1.08192831e+12, 9.19784781e+11,
8.64234606e+11, 9.02426244e+11, 8.96488076e+11,
8.52519489e+11, 8.28115493e+11, 7.98496774e+11,
7.63979130e+11],
[ 8.64233389e+11, 9.19784781e+11, 1.08192869e+12,
9.19785555e+11, 8.64234241e+11, 9.02427089e+11,
8.96489010e+11, 8.52519220e+11, 8.28114928e+11,
7.98496806e+11],
[ 9.02427205e+11, 8.64234606e+11, 9.19785555e+11,
1.08193006e+12, 9.19785087e+11, 8.64236205e+11,
9.02428512e+11, 8.96489037e+11, 8.52518449e+11,
8.28114559e+11],...

</pre>
                <p class="text-lg mt-3">
                    We can see that it is a 10x10 matrix in our example for a Wiener filter with 10 filter
                    taps. In this matrix, the next row looks almost like the previous line, but shifted by 1
                    sample to the right.
                    Observe that in general this matrix AT
                    ¬∑ A converges to the autocorrelation matrix of
                    signal y(n) if the length of the signal in the matrix goes to infinity!
                </p>

                <div class="text-center mt-3 text-lg font-mono">


                    <p class="text-lg font-mono mt-3 text-center"
                        appMathJax="$$ 
{A}^T \cdot {A} \to {R}_{yy} = \begin{bmatrix} r_{yy}(0) & r_{yy}(1) & r_{yy}(2) & \ldots \\ r_{yy}(1) & r_{yy}(0) & r_{yy}(1) & \ldots \\ \vdots & \vdots & \vdots & \vdots \end{bmatrix} $$">
                    </p>


                </div>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
r_{yy}(m) = \sum_{n=-\infty}^{\infty} y(n) \cdot y(n+m)
 $$"></p>

                <p class="text-lg mt-3">
                    Since one row of this matrix is the shifted-by-one-sample version of the one above, it is called a
                    Toeplitz Matrix ‚Äî Wikipedia link.
                </p>

                <p class="text-lg mt-3">
                    The expression (A^T ¬∑ x^T) in our formulation of the Wiener filter becomes the cross-correlation
                    vector:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A}^T \cdot {x}^T \to {r}_{xy} = \begin{bmatrix} r_{xy}(0) \\ r_{xy}(1) \\ \vdots \end{bmatrix} $$"></p>


                <p class="text-lg mt-3">
                    where the cross-correlation function is defined as:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
r_{xy}(m) = \sum_{n=-\infty}^{\infty} y(n) \cdot x(n+m) $$"></p>


                <p class="text-lg mt-3">
                    Observe:<br>
                    In the receiver, we usually don‚Äôt have the un-noisy signal x(n), but we can estimate the above
                    cross-correlation function.
                </p>

                <p class="text-lg mt-3">
                    Hence, our expression for the Wiener filter becomes:<br>

                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}^T = ({A}^T \cdot {A})^{-1} {A}^T \cdot {x}^T $$"></p>

                <p>
                    becomes
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}^T = ({R}_{yy})^{-1} {r}_{xy} $$"></p>

                <p class="text-lg mt-3">
                    This matrix form is also called the Yule‚ÄìWalker equation, and the general statistical formulation is
                    called the Wiener‚ÄìHopf equation.
                </p>

                <p class="text-lg mt-3">
                    This general statistical formulation also has the advantage that we can design a Wiener Filter by
                    just knowing the statistics ‚Äî the auto-correlation function of our noisy signal, and the
                    cross-correlation function of our noisy and original signal.
                </p>

                <p class="text-lg mt-3">
                    Observe that this auto-correlation and cross-correlation can also be obtained from the power spectra
                    (cross-power spectra ‚Äî the product of the two spectra) of the respective signals.
                </p>

                <p class="text-lg mt-3">
                    The power spectrum of the noisy signal can usually be measured, since it is the signal to be
                    filtered, and the spectrum of the original signal x(n) usually has to be estimated (using
                    assumptions about it). For instance, we know typical speech spectra.
                </p>

                <p class="text-lg mt-3">
                    If we want to adapt a Wiener filter in a receiver, we take this typical speech spectrum and measure
                    the noise level at the receiver. Then, we can add the power spectrum of the noise to the power
                    spectrum of the speech to obtain the power spectrum of the noisy speech (which is the power
                    cross-spectrum of the clean speech and noise, or the Fourier Transform of the cross-correlation,
                    because we assume the speech and the noise are uncorrelated).
                </p>
                <p class="text-lg mt-3">
                    To use **Wiener‚ÄìHopf**,

                    we simply apply the **inverse Fourier Transforms** to the power spectra.

                    That is sufficient to compute the Wiener filter coefficients,

                    using the formulations above.
                </p>

            </mat-card-content>
        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-xl font-semibold  text-blue-700">12.2 Matched Filters</h3>


                <p class="text-lg mt-3">
                    Remember the goal of a matched filter (h_M(n)):
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y(n) * h_M(n) \to x(n+n_d) * h_M(n)
 $$"></p>

                <p class="text-lg mt-3">
                    with some signal delay (n_d). The objective is not signal fidelity but a high SNR at detection time.
                    Here
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
y(n) = x(n+n_d) + v(n)
 $$"></p>


                <p class="text-lg mt-3">
                    is our delayed signal with additive noise v(n).
                </p>

                <p class="text-lg mt-3">
                    Application examples include communications, where you want to detect a 0 or 1 ‚Äî for example in
                    <strong>CDMA</strong>, where each user has a unique pseudo-random 1/0 sequence (chip-sequences) to
                    represent symbols; different users/signals are separated using matched filters.
                </p>

                <p class="text-lg mt-3">
                    Another example is detecting known signals or patterns, such as object or face recognition in
                    images. In general, matched filters are used to detect deterministic signals x(n).
                </p>

                <p class="text-lg mt-3">
                    The goal is to maximize the signal-to-noise ratio (SNR) at the instant of detection for the original
                    signal x(n) and noise v(n). The SNR can be written as:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
SNR = \frac{|x(n) * h_M(n)|^2}{E(|v(n) * h_M(n)|^2)}
 $$"></p>

                <p class="text-lg mt-3">
                    We want to maximize the SNR at the time of detection using the matched filter h_M(n).
                </p>

                <p class="text-lg mt-3">
                    To do this, we assume that v(n) is independent white noise. Under this assumption, the denominator
                    of the SNR becomes a fixed, known power value.
                </p>

                <p class="text-lg mt-3">
                    Using the matrix V that contains the noise samples and the row vector h_M that contains the filter
                    coefficients, we obtain:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\begin{align*}
E(|v(n) * h_M(n)|^2) &= E(|{V} \cdot {h}_M^T|^2) \\
&= E({h}_M \cdot {V}^T \cdot {V} \cdot {h}_M^T)\\
&= {h}_M \cdot E({V}^T \cdot {V}) \cdot {h}_M^T\\
&= {h}_M \cdot \sigma_v^2 \cdot {I} \cdot {h}_M^T \\
&= \sigma_v^2 \cdot {h}_M \cdot {h}_M^T
\end{align*}
 $$"></p>

                <p class="text-lg mt-3">
                    White noise has an autocorrelation function shaped like a weighted delta function, because each
                    noise sample is uncorrelated with its neighbors and only correlated with itself. That correlation
                    equals the noise power (sigma_v squared).
                </p>

                <p class="text-lg mt-3">
                    Therefore, the autocorrelation matrix E(V^T multiplied by V) has zeros everywhere except on the
                    diagonal, where each diagonal element equals the noise power. This means the matrix equals sigma_v
                    squared times the identity matrix I.
                </p>

                <p class="text-lg mt-3">
                    The final expression above is simply the squared norm (sum of squares) of the vector of filter
                    coefficients h_M, multiplied by the noise power sigma_v squared.
                </p>

                <p class="text-lg mt-3">
                    Keeping the above norm of our filter vector (h_M * h_M^T) constant, the entire denominator is fixed,
                    and we only need to maximize the numerator of our SNR fraction to maximize the SNR:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
|x(n) * h_M(n)|^2
 $$"></p>

                <p class="text-lg mt-3">
                    We rewrite our numerator as:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
|x(n) * h_M(n)|^2 = |x(n) \cdot {h}_M^T|^2
 $$"></p>

                <p class="text-lg mt-3">
                    This is written analog to our matrix formulation, as a scalar vector multiplication, with h_M as our
                    row vector of the matched filter impulse response, and now with only one row of the signal matrix A
                    (from last time) at a time, for only one convolution sample at a time.
                </p>

                <p class="text-lg mt-3">
                    Observe that for matched filters the signal to detect can be much shorter than for the Wiener
                    filter, and hence we can decide to make the matched filter the same size as our signal to detect.
                </p>

                <p class="text-lg mt-3">
                    The signal row vector is:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{x}(n) = [x(L - 1 - n), x(L - 2 - n), \ldots, x(n)]
 $$"></p>

                <p class="text-lg mt-3">
                    where L is the size of our filter vector. Observe that it is time-reversed to obtain a value of the
                    convolution.
                </p>

                <p class="text-lg mt-3">
                    We apply the Cauchy‚ÄìSchwarz inequality (see Wikipedia), which states that for two column vectors a
                    and b, their scalar product satisfies:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
a^T b \le \sqrt{a^T a}\,\sqrt{b^T b}
 $$"></p>

                <p class="text-lg mt-3">
                    This is also written using the norm |a| and the inner product &lt;a, b&gt; as:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
|\langle {a}, {b} \rangle| \leq \|{a}\| \cdot \|{b}\|
 $$"></p>

                <p class="text-lg mt-3">
                    We obtain equality if both vectors are co-linear, meaning b = k ¬∑ a for some scalar k.
                </p>

                <p class="text-lg mt-3">
                    This tells us how to solve the maximization task.
                </p>

                <p class="text-lg mt-3">
                    We can now apply the Cauchy‚ÄìSchwarz inequality if we set a = x(n) and b = h_M:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
|{x}(n) \cdot {h}_M^T|^2 \leq \|{x}(n)\|^2 \cdot \|{h}_M\|^2
 $$"></p>

                <p class="text-lg mt-3">
                    We get equality (the maximum) if we set:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}_M = k \cdot {x}(n)
 $$"></p>

                <p class="text-lg mt-3">
                    where we can choose the factor k = 1.
                </p>

                <p class="text-lg mt-3">
                    Since we have this inequality for all time steps n of our convolution, we choose the time index n
                    where the row vector x(n) has the maximum energy.
                </p>

                <p class="text-lg mt-3">
                    This is the point where we capture the entire non-zero waveform of our signal x(n) with our filter.
                </p>

                <p class="text-lg mt-3">
                    Since our filter vector h_M contains the time-reversed impulse response, we obtain the entire
                    time-reversed signal as our matched filter:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
h_M(n) = x(L - 1 - n)
 $$"></p>

                <p class="text-lg mt-3">
                    Assuming our signal to detect is located between 0 ‚â§ n &lt; L.
                </p>

                <p class="text-lg mt-3">
                    Since we have a convolution of the signal with its time-reversed version, we get a convolution
                    length of (2L ‚àí 1) samples, with its maximum at the center, when both waveforms completely overlap.
                    This happens after L samples, which is exactly the signal length.
                </p>

                <p class="text-lg mt-3">
                    Hence we get the <b>detection of our signal</b> after we have completely received it, at the end of
                    our signal.
                </p>

                <p class="text-lg mt-3"><b>Observe:</b></p>

                <p class="text-lg mt-3">
                    Since we convolve the signal with the time-reversed version of the pattern to be detected, this is
                    identical to computing the <b>correlation</b> of the signal with the pattern to be detected.
                </p>

                <p class="text-lg mt-3"><b>Also observe:</b></p>

                <p class="text-lg mt-3">
                    The longer the signal is, the more energy is captured in it, and the higher the <b>SNR</b> will be
                    at the time of detection.
                </p>

                <p class="text-lg mt-3">
                    This is important for very weak signals, for example in <b>deep space communications</b>.
                </p>

                <p class="text-lg mt-3"><b>In conclusion:</b>
                    The matched filter has the shape of the time-reversed signal that we want to detect.
                </p>




            </mat-card-content>

        </mat-card>


    </div>
    <div class="flex flex-col justify-around items-center gap-2">
        <img src="assets/images/chap12/fig12.2.png" class="w-150 h-80 ">
        <h1 class="text-wrap">

        </h1>
    </div>

    <div class="flex flex-col justify-around items-center gap-2">
        <img src="assets/images/chap12/fig12.3.png" class="w-150 h-80 ">
        <h1 class="text-wrap">

        </h1>
    </div>

    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-xl font-semibold font-sans mb-3" style="color: blue;">12.2.1 Python Example
                </h3>

                <p class="text-lg mt-3">
                    Construct a signal to be detected, sig (length 11):
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

ipython --pylab
sig = arange(0, 1.1, 0.1)
sig
#Out: array([ 0. , 0.1, 0.2, 0.3, 0.4, 0.5, #0.6, 0.7, 0.8, 0.9, 1. ])
plot(sig)
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôAn Example Signal‚Äô)

</pre>
                <p class="mt-2">
                    The resulting plot can be seen in Fig. (12.13). We put this signal to detect at some
                    point in time in a longer signal,
                </p>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.4.png" class="w-180 h-110 ">


                </div>



                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

sig\_inzeros=hstack([zeros(4),sig,zeros(5)])
plot(sig\_inzeros)
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôThe Signal at Some Point in Time‚Äô)

</pre>

                <p class="mt-2">
                    The resulting plot can be seen in Fig. (12.14). Now we add noise and extend the length of our signal
                </p>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.5.png" class="w-180 h-110 ">


                </div>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

signoise = random.rand(20)-0.5+sig\_inzeros
plot(signoise)
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôThe Example Signal in Noise‚Äô)
The resulting plot can be seen in Fig. (12.15). Now we apply our matched filter to it:
h = sig[::-1] # fliplr
signoisemf = sp.lfilter(h, 1, signoise)
plot(signoisemf)
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôThe Example Signal in Noise after Macthed Filtering‚Äô)

</pre>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.6.png" class="w-180 h-110 ">


                </div>
                <p class="mt-2">
                    The resulting plot can be seen in Fig. (12.16). This is now the output of our matched
                    filter. We can see that we have a maximum at time 14, which marks the end of our
                    detected signal. Hence we know that the signal started at sample 14-L(length of the
                    filter)=14-11=3, which was indeed the case since we added 4 zeros in the beginning. So
                    matched filtering did a good job!
                    The matched filtering process can also be viewed as computing the correlation of the
                    noisy signal with the original signal.
                </p>
            </mat-card-content>

        </mat-card>


    </div>


    <div class="flex flex-col justify-around items-center gap-2">
        <img src="assets/images/chap12/fig12.7.png" class="w-130 h-60 ">
        <h1 class="text-wrap">

        </h1>
    </div>

    <div class="flex flex-col justify-around items-center gap-2">
        <img src="assets/images/chap12/fig12.8.png" class="w-130 h-60 ">
        <h1 class="text-wrap">

        </h1>
    </div>




    <div>

        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-xl font-semibold font-sans mb-3" style="color: blue;">12.2.2 Convolutional Neural Network
                    Implementation
                </h3>


                <p class="text-lg mt-3">
                    Observe that we got a high peak for the detection of our signal, but the peak was somewhat broad,
                    which makes determining the precise location of the signal more difficult.
                    This is because we specified as a target for our optimization that we want to have a
                    high peak, but not necessarily a narrow peak. To remedy this, we can use numerical
                    optimization instead of our closed form solution for matched filters.
                    For that, we can use the optimization of a neural network library, like Pythons ‚ÄúPytorch‚Äù. Pytorch
                    has the advantage, compared to e.g. Keras, that ‚Äúprint‚Äù commands
                    work, which is important and useful for debugging.
                    The following example also serves as a short introduction into neural networks and its
                    terminology
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.7.png" class="w-130 h-60 ">

                </div>


                <p class="text-lg mt-3">
                    We can implement our filter using a 1-dimensional ‚Äúconvolutional layer‚Äù, object conv1d,
                    without ‚Äúbias‚Äù and without a non-linear ‚Äúactivation function‚Äù.
                    The library ‚ÄúPytorch‚Äù is obtained and installed from www.pytorch.org.
                    For it we need to specify a ‚Äútraining‚Äù signal, here our signal to detect (the ‚Äúramp‚Äù
                    function) x, and the ‚Äútarget‚Äù signal y, which is the desired output of the convolutional
                    layer which the optimization should reach as closely as possible during the optimization
                    or ‚Äútraining‚Äù
                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

Our training set is:
x= np.hstack((np.zeros(4),np.arange(0,1.1,0.1),np.zeros(5)))
y = np.zeros(30)
y[16]=1 #Detecting the signal at its end

</pre>

                <p class="text-lg mt-3">
                    Observe that for the target y we specified a single peak (the ‚Äú1‚Äù) at the position
                    the filter should detect the signal, and zeros everywhere else. This also leads to a
                    minimization of the output outside the signal detection, which we didn‚Äôt have in our
                    closed form solution! We specify our convolutional detector layer as,
                    detector=nn.Sequential(nn.Conv1d(in_channels=1, out_channels=1, kernel_size=11,
                    stride=1, padding=10, bias=False))
                </p>


                <p class="text-lg mt-3">
                    Observe that for the target y we specified a single peak (the ‚Äú1‚Äù) at the position
                    the filter should detect the signal, and zeros everywhere else. This also leads to a
                    minimization of the output outside the signal detection, which we didn‚Äôt have in our
                    closed form solution! We specify our convolutional detector layer as,
                    detector=nn.Sequential(nn.Conv1d(in_channels=1, out_channels=1, kernel_size=11,
                    stride=1, padding=10, bias=False))
                </p>

                <p class="text-lg mt-3">
                    python3 pytorch_simpl_convnet_detector.py
                    We use the same type as input as before. The resulting plot can be seen in Fig.
                    (12.17). The figure shows the obtained weights or coefficients, in pytorch they are used
                    as correlation instead of convolution, and hence the plot is a time-reversed impulse
                    response.
                </p>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.8.png" class="w-130 h-60 ">

                </div>





                <p class="text-lg mt-3">
                    The resulting plot can be seen in Fig. (12.18). Observe that it looks indeed different
                    from our matched filter, which was simply the (time-reversed) ramp signal. This is
                    because the optimization also tries to minimized the output outside the detection time
                    point.

                </p>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.9.png" class="w-130 h-60 ">

                </div>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.10.png" class="w-130 h-60 ">

                </div>




            </mat-card-content>

        </mat-card>


    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans mb-3" style="color: rgb(13, 13, 13);">
                    12.3 Prediction
                </h3>
                <p class="text-lg mt-3">
                    Prediction can be seen as a special case of a Wiener filter, where the noise of our signal
                    corresponds to a shift of our signal into the past.

                    Our goal is to make a ‚Äúgood‚Äù estimation of the present sample of our signal, based on past signal
                    samples.

                    ‚ÄúGood‚Äù here means, again, in a mean squared error sense.


                </p>

                <p class="text-lg mt-3">
                    Basically, we can now take our Wiener Filter formulation and specialize it to this case.


                </p>


                <p class="text-lg mt-3">Looking at our matrix formulation, we get:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\begin{bmatrix} x(1) & x(0) \\ x(2) & x(1) \\ x(3) & x(2) \\ \vdots & \vdots \end{bmatrix} \cdot \begin{bmatrix} h(0) \\ h(1) \end{bmatrix} = \begin{bmatrix} x(2) \\ x(3) \\ x(4) \\ \vdots \end{bmatrix}
 $$"></p>

                <p class="text-lg mt-3">or</p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A} \cdot {h}^T \to {x}

 $$"></p>


                <p class="text-lg mt-3">
                    This means the input to our filter is always starting at one sample in the past, going further down
                    into the past.
                    Its goal is to estimate or ‚Äúpredict‚Äù the next coming sample.
                </p>

                <p class="text-lg mt-3">
                    Basically, this means that instead of additive white noise, our distortion is now a <b>delay
                        operator</b> (which is still a linear operator).
                </p>

                <p class="text-lg mt-3">
                    Now we can again use our approach with pseudo-inverses to obtain the mean-squared-error solution:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h} = ({A}^T \cdot {A})^{-1}{A}^T \cdot {x}
 $$"></p>


                <p class="text-lg mt-3">
                    with the matrix A defined as above.
                </p>

                <p class="text-lg mt-3">
                    This now also leads to a statistical description, with A·µÄ * A converging to:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A}^T \cdot {A} \to {R}_{xx} = \begin{bmatrix} r_{xx}(0) & r_{xx}(1) & r_{xx}(2) & \ldots \\ r_{xx}(1) & r_{xx}(0) & r_{xx}(1) & \ldots \\ \vdots & \vdots & \vdots & \ddots \end{bmatrix}
 $$"></p>

                <p class="text-lg mt-3">
                    This is plausible because now y(n) is just the delayed signal, and the auto-correlation function of
                    the delayed signal is the same as that of the original signal.
                </p>


                <p class="text-lg mt-3">Next, we need the cross-correlation A<sup>T</sup> * x.</p>

                <p class="text-lg mt-3">Since we now just have this one sample in the future as our target vector, this
                    converges to the
                    auto-correlation vector starting at lag 1:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{A}^T \cdot {x} \to {r}_{xx} = \begin{bmatrix} r_{xx}(1) \\ r_{xx}(2) \\ \vdots \end{bmatrix}
 $$"></p>


                <p class="text-lg mt-3">So together, we get the solution for our prediction filter as:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h} = ({R}_{xx})^{-1} {r}_{xx}
 $$"></p>


                <br>

                <p class="text-lg mt-3">A system that produces the prediction error (for example, as part of an encoder)
                    can be seen below:
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.11.png" class="w-180 h-110 ">


                </div>




                <p class="text-lg mt-3">
                    Here, x(n) is the signal to be predicted. H(z) is our prediction filter, whose coefficients
                    are obtained using the Wiener approach from the previous lecture slides:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h} = ({R}_{xx})^{-1} {r}_{xx}
 $$"></p>
                <p class="text-lg mt-3">
                    H(z) is simply the z-transform of that filter. It operates only on past samples
                    (which is why the delay element z<sup>-1</sup> appears before it).
                </p>

                <p class="text-lg mt-3">
                    xÃÇ(n) is the predicted signal, and the prediction error is:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
e(n) = x(n) - \hat{x}(n)
 $$"></p>


                <p class="text-lg mt-3">
                    Thus, the system that produces the prediction error has the z-domain transfer function:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
H_{err}(z) = 1 - z^{-1} \cdot H(z)
 $$"></p>

                <p class="text-lg mt-3">This can function as an encoder. Observe that we can reconstruct the original
                    signal x(n) in a
                    decoder from the prediction error e(n), using the system shown in Figure 12.12.</p>

                <p class="text-lg mt-3">Recall that the encoder computed:</p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.12.png" class="w-180 h-110 ">


                </div>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
e(n) = x(n) - \hat{x}(n)
 $$"></p>


                <p class="text-lg mt-3">
                    The feedback loop in the decoder is causal because it only uses past, already reconstructed samples.
                </p>

                <p class="text-lg mt-3">Observe that the decoder's transfer function is:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
H_{rec}(z) = \frac{1}{1 - z^{-1} \cdot H(z)} = \frac{1}{H_{perr}(z)}
 $$"></p>


                <p class="text-lg mt-3">
                    This is exactly the inverse of the encoder, as expected.
                </p>

            </mat-card-content>

        </mat-card>
    </div>



    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.4 Python Example
                </h3>


                <p class="mt-4">


                    Goal: Construct a prediction filter for our female speech signal of order L=10, which
                    minimizes the mean-squared prediction error. Read in the female speech sound
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

ipython3 --pylab

from sound import *

# Read audio
x, fs = wavread('fspeech.wav')
shape(x)
# Out: (207612,)

# Make x a float matrix, transpose to column, normalize to -1 < x < 1
x = matrix(x, dtype=float).T / 2**15

# Listen to it (convert matrix back to array)
sound(array(x.T)[0] * 2**15, fs)

# Construct matrix A from x
A = matrix(zeros((100000, 10)))
for m in range(0, 100000):
    A[m, :] = flipud(x[m + arange(10)]).T

# Construct desired target signal d
# One sample into the future
# First 10 samples fill the prediction filter,
# The 11th sample is the first to be predicted
d = x[arange(10, 100010)]

# Compute the prediction filter
h = inv(A.T * A) * A.T * d
h

# Example output:
# matrix([[ 0.90078449],
#        [-0.7764783 ],
#        [ 1.17924513],
#        [-0.45849443],
#        [ 0.62230755],
#        [-0.32026094],
#        [ 0.05412175],
#        [-0.20557095],
#        [-0.01108994],
#        [-0.03070101]])

plot(h)
xlabel('Sample')
ylabel('Value')
title('Impulse Response of our Prediction Filter')

</pre>

                <p class="mt-4">
                    The resulting plot can be seen in Fig. (12.13). Then our prediction filter, with the delay in the
                    encoder becomes (to compare it with the original signal):
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

hpred = vstack([0, h])
The predicted values are now obtained by applying these coefficients as an FIR filter:
import scipy.signal as sp
xpred = sp.lfilter(array(hpred.T)[0],1,array(x.T)[0])
Now we can plot the predicted values on top of the actual original signal values, to seeplot(x);
plot(xpred,‚Äôred‚Äô)
legend((‚ÄôOriginal‚Äô,‚ÄôPredicted‚Äô))
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôOur Speech Wave Form‚Äô)

</pre>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.13.png" class="w-180 h-110 ">


                </div>

                <p class="mt-4">
                    The resulting plot can be seen in Fig. (12.14). Our corresponding prediction error
                    filter (which is in the encoder) is
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
H_{err}(z) = 1 - z^{-1} \cdot H(z)
 $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
h_{err} = \begin{bmatrix} 1 \\ -0.90078449 \\ 0.7764783 \\ -1.17924513 \\ 0.45849443 \\ -0.62230755 \\ 0.32026094 \\ -0.05412175 \\ 0.20557095 \\ 0.01108994 \\ 0.03070101 \end{bmatrix}
 $$"></p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">


#The prediction error e(n) is obtained using our prediction error filter:
e = sp.lfilter(array(hperr.T)[0],1,array(x.T)[0]);
#make a matrix type out of it (row matrix):
e=matrix(e)
#error power per sample:
e*e.T/max(shape(e))
#Out: matrix([[ 0.00043284]])

#Compare that with the mean squared signal power per sample:
x.T*x/max(shape(x))
Out[26]: matrix([[ 0.00697569]])
#Which is more than 10 times as big as the prediction error! Which shows that it works!
#Listen to the error signal:
sound(2**15*array(e)[0],fs)
#Take a look at the signal and it‚Äôs prediction error:
plot(2**15*x)
plot(2**15*e.T,‚Äôr‚Äô)
xlabel(‚ÄôSample‚Äô)
ylabel(‚ÄôValue‚Äô)
title(‚ÄôOur Speech and Prediction Error Wave Forms‚Äô)
legend((‚ÄôOriginal‚Äô, ‚ÄôPrediction Error‚Äô))
                </pre>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.14.png" class="w-180 h-110 ">


                </div>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
H_{rec} = \frac{1}{1 - z^{-1} \cdot H(z)} = \frac{1}{H_{perr}(z)}
 $$"></p>

                <p class="mt-4">
                    The resulting plot can be seen in Fig. (12.15). The decoder uses the reverse filter hence we use the
                    following filter command to generate the reconstructed signal,
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

xrec = sp.lfilter([1],array(hperr.T)[0], array(e)[0]);
#plot original for comparison:
plot(x)
#Plot decoded reconstructed on top in red:
plot(xrec,‚Äôr‚Äô)
#We can listen to it with:
sound(2**15*array(xrec),fs)

                </pre>

                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.15.png" class="w-180 h-110 ">


                </div>
                <p class="mt-4">
                    Observe: The decoded, reconstructed signal looks and sound identical to the original,
                    as expected. This means we can indeed use it in an encoder-decoder setting
                </p>
                <p class="mt-4">

                </p>


            </mat-card-content>

        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.5 Neural Network Implementation
                </h3>


                <p class="mt-4">


                    Again, we can also use the numerical optimization of **PyTorch** instead of our closed-form solution
                    from **Wiener‚ÄìHopf**, and a `conv1d` layer.

                </p>
                We also use the **mean squared error** as the minimization criterion or ‚Äúloss function‚Äù.
                <p class="mt-4">
                    In this case, this does not differ from the target of the closed-form formulation, and hence we
                    obtain almost the same solution.

                </p>
                <p class="mt-4">
                    Here, the desired target signal **Y** is the audio input signal **X**, but 1 sample in the future.

                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

X = audio[:-L]    # remove last samples (conv makes it longer again)
Y = audio[1:]     # remove first sample, for the signal to predict
                   # 1 sample in the future


</pre>
                <p class="mt-4">

                    ‚Äã
                    We can let it run and see it with:
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

python3 pytorch_linpred_inputs.py

</pre>



            </mat-card-content>

        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.6 Online Adaptation, LPC
                </h3>


                <p class="mt-4">
                    The previous example calculated the prediction coefficients for the entire speech file
                    (or the first 100,000 samples).
                </p>

                <p class="mt-4">
                    But when we look at the signal waveform, we see that its characteristics ‚Äî and hence its
                    statistics ‚Äî are changing; it is not stationary.
                </p>

                <p class="mt-4">
                    Hence, we can expect a prediction improvement if we divide the speech signal into small
                    pieces for the computation of the prediction coefficients ‚Äî pieces which are small enough
                    to show roughly constant statistics.
                </p>

                <p class="mt-4">
                    In speech coding, those pieces are usually of length 20 ms, and this approach is called
                    Linear Predictive Coding (LPC).
                </p>

                <p class="mt-4">
                    Here, the prediction coefficients are calculated usually every 20 ms, and then transmitted
                    alongside the prediction error, from the encoder to the decoder.
                </p>

                <p class="mt-4">
                    This also has the advantage that it needs no training set, and computes the coefficients
                    from the actual samples in the current block.
                </p>

                <p class="mt-4">
                    Observe that this also needs a very fast optimization ‚Äî hence, the PyTorch approach
                    with the Adam optimizer would not be suitable.
                </p>

                <p class="mt-4">
                    We use our faster closed-form solution instead.
                </p>


            </mat-card-content>

        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.6.1 Python Example
                </h3>


                <p class="mt-4">


                    Our speech signal is sampled at 32 kHz, hence a block of 20 ms has 640 samples. We
                    write a python file with name ‚Äú[lpcexample.py](http://lpcexample.py/)‚Äù, with the following content,
                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

import numpy as np
from sound import *
import matplotlib.pyplot as plt
import scipy.signal as sp

x, fs = wavread('fspeech.wav');

# convert to float array type, normalize to -1 < x < 1:
x = np.array(x, dtype=float) / 2**15

print np.size(x)

sound(2**15 * x, fs)

L = 10  # predictor length
len0 = np.max(np.size(x))

e = np.zeros(np.size(x))  # prediction error variable initialization
blocks = np.int(np.floor(len0 / 640))  # total number of blocks
state = np.zeros(L)  # Memory state of prediction filter

# Building our Matrix A from blocks of length 640 samples and process:
for m in range(0, blocks):
    A = np.zeros((640 - L, L))  # trick: up to 630 to avoid zeros
    for n in range(0, 640 - L):
        A[n, :] = np.flipud(x[m * 640 + n + np.arange(L)])

    # Construct our desired target signal d, one sample into the future:
    d = x[m * 640 + np.arange(L, 640)]

    # Compute the prediction filter:
    h = np.dot(np.dot(np.linalg.inv(np.dot(A.transpose(), A)), A.transpose()), d)

    hperr = np.hstack([1, -h])

    e[m * 640 + np.arange(0, 640)], state = sp.lfilter(
        hperr, [1], x[m * 640 + np.arange(0, 640)], zi=state
    )

# The mean-squared error now is:
print "The average squared error is:", np.dot(e.transpose(), e) / np.max(np.size(e))
# The average squared error is: 0.000113347859337

# Compare with signal power:
print "Compare that with the mean squared signal power:",
np.dot(x.transpose(), x) / np.max(np.size(x))
# 0.00697569381701

print "The Signal to Error ratio is:", np.dot(x.transpose(), x) / np.dot(e.transpose(), e)
# 61.5423516403

# So our LPC pred err energy is more than a factor of 61 smaller than the signal energy!
# Listen to the prediction error:
sound(2**15 * e, fs)

# Take a look at the signal and its prediction error:
plt.figure()
plt.plot(x)
plt.plot(e, 'r')
plt.xlabel('Sample')
plt.ylabel('Normalized Value')
plt.legend(('Original', 'Prediction Error'))
plt.title('LPC Coding')
plt.show()

# Decoder:
xrek = np.zeros(x.shape)  # initialize reconstructed signal memory
state = np.zeros(L)       # initialize memory state of prediction filter

for m in range(0, blocks):
    hperr = np.hstack([1, -h[m, :]])
    # predictive reconstruction filter:
    xrek[m * 640 + np.arange(0, 640)], state = sp.lfilter(
        [1], hperr, e[m * 640 + np.arange(0, 640)], zi=state
    )

# Listen to the reconstructed signal:
sound(2**15 * xrek, fs)

</pre>
                <p class="mt-4">
                    Now execute the program with python lpcexample.py
                    The resulting plot can be seen in Fig. (12.16). Here it can be seen that the prediction
                    error is even smaller than before.
                    The decoder works the way as shown in the previous example, and the reconstructed
                    speech can be heard in the end.

                </p>
                <p class="mt-4">
                    LPC type coders are for instance speech coders, where usually 12 coefficients are used
                    for the prediction, and transmitted as side information every 20 ms. The prediction
                    error is parameterized and transmitted as parameters with a very low bit rate. This
                    kind of system is used for instance in most digital cell phones systems.
                </p>

            </mat-card-content>

        </mat-card>
    </div>






    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.7 Least Mean Squares (LMS) Algorithm
                </h3>


                <p class="mt-4">
                    Unlike the LPC algorithm above, which computes prediction coefficients for a block of
                    samples and transmits these coefficients alongside the prediction error to the receiver,
                    the LMS algorithm updates the prediction coefficients after each sample, but based only
                    on past samples. Hence here we need the assumption that the signal statistics does not
                    change much from the past to the present. Since it is based on the past samples, which
                    are also available as decoded samples at the decoder, we do not need to transmit the
                    coefficients to the decoder. Instead, the decoder carries out the same computations in
                    synchrony with the encoder.
                    Instead of a matrix formulation, we use an iterative algorithm to come up with a
                    solution for the prediction coefficients h the vector which contains the time-reversed
                    impulse response of our predictor.
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.16.png" class="w-180 h-110 ">


                </div>


                <p class="mt-4">
                    To show the dependency on the time n, we now call the vector of prediction coefficients h(n), with:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}(n) = [h_0(n), h_1(n), \ldots, h_{L-1}(n)]
 $$"></p>


                <p class="mt-4">
                    Again, we want to minimize the mean squared prediction error, with the prediction error defined as:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
e(n) = x(n) - \hat{x}(n)
 $$"></p>


                <p class="mt-4">
                    The mean squared prediction error is:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
E\left[(x(n) - \hat{x}(n))^2\right] = E\left[\left(x(n) - \sum_{k=0}^{L-1} h_k(n) x(n - 1 - k)\right)^2\right]
 $$"></p>


                <p class="mt-4">
                    Instead of using the closed-form solution that leads to the Wiener-Hopf solution, we now take an
                    iterative approach using Steepest Descent (also called Gradient Descent). We iterate toward the
                    minimum using:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}(n + 1) = {h}(n) - \alpha \cdot \nabla f({h}(n))
 $$"></p>


                <p class="mt-4">
                    The objective (error) function is simply the squared prediction error:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
f({h}(n)) = \left(x(n) - \sum_{k=0}^{L-1} h_k(n) x(n - 1 - k)\right)^2
 $$"></p>


                <p class="mt-4">
                    Observe that we omit the expectation operator E for simplicity. After several update steps,
                    averaging occurs inherently due to the stochastic nature of the iterations. This is also known as
                    ‚ÄúStochastic Gradient Descent‚Äù.
                </p>

                <p class="mt-4">
                    The gradient is the row vector:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\nabla f(n) = \left[\frac{\partial f({h}(n))}{\partial h_0(n)}, \ldots, \frac{\partial f({h}(n))}{\partial h_{L-1}(n)}\right]
 $$"></p>


                <p class="mt-4">
                    and the individual derivatives are obtained as:
                </p>
                <p class="mt-4">
                    We now compute the individual derivatives of the error function.
                    For each coefficient h_k(n), the derivative is:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
\frac{\partial f({h}(n))}{\partial h_k(n)} = 2 \cdot e(n) \cdot (-x(n - 1 - k))
 $$"></p>


                <p class="text-center mt-3 text-lg font-mono">
                    for k = 0, 1, ..., L ‚àí 1.
                </p>

                <p class="mt-4">
                    Putting this into the steepest descent update gives the LMS update rule:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
h_k(n + 1) = h_k(n) + \alpha \cdot e(n) \cdot x(n - 1 - k)
 $$"></p>

                <p class="mt-4">
                    for k = 0, ..., L ‚àí 1.
                    The factor 2 is absorbed into the step-size Œ±.
                    The parameter Œ± controls the tradeoff between convergence speed and accuracy.
                    A discussion of choosing Œ± can be found in the lecture slide set 15 of the course ‚ÄúMultirate Signal
                    Processing‚Äù.
                </p>

                <p class="mt-4">
                    In vector form, the LMS update rule becomes:
                </p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{h}(n + 1) = {h}(n) + \alpha \cdot e(n) \cdot {x}(n)
 $$"></p>

                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
{x}(n) = [x(n - 1), x(n - 2), \ldots, x(n - L)]
 $$"></p>



                <p class="mt-4">
                    Note that this method requires no matrices or matrix inverses.
                    It uses only this simple update rule, yet it still converges to the correct prediction coefficients.
                </p>

                <p class="mt-4">
                    For the prediction coefficients h, the vector x(n) acts as a ‚Äúsliding window‚Äù of the past L samples
                    of the signal.
                </p>

                <p class="mt-4">
                    Different approaches exist for choosing Œ±.
                    One popular method is the Normalized LMS (NLMS), which uses the inverse of the signal power as Œ±.
                    If the signal power is 1, then Œ± can be set to 1.
                    In general, Œ± is chosen by hand through experimentation.
                </p>


                <p class="text-center mt-3 text-lg font-mono">
                    formula
                </p>
            </mat-card-content>

        </mat-card>
    </div>

    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.7.1 LMS Python Example
                </h3>


                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

import numpy as np
from sound import *
import matplotlib.pyplot as plt

x, fs = wavread('fspeech.wav')

# normalized float, -1 < x < 1
x = np.array(x, dtype=float) / 2**15

print np.size(x)

e = np.zeros(np.size(x))
h = np.zeros(10)

for n in range(10, len(x)):
    # prediction error and filter, using the vector of the time reversed IR:
    e[n] = x[n] - np.dot(np.flipud(x[n-10+np.arange(0,10)]), h)

    # LMS update rule, according to the definition above:
    h = h + 1.0 * e[n] * np.flipud(x[n-10+np.arange(0,10)])

print "Mean squared prediction error:", np.dot(e, e) / np.max(np.size(e))
# 0.000215852452838

print "Compare that with the mean squared signal power:", np.dot(x.transpose(), x) / np.max(np.size(x))
# 0.00697569381701

print "The Signal to Error ratio is:", np.dot(x.transpose(), x) / np.dot(e.transpose(), e)
# 32.316954129056604, half as much as for LPC.

# listen to the prediction error:
sound(2**15 * e, fs)

plt.figure()
plt.plot(x)
plt.plot(e, 'r')
plt.xlabel('Sample')
plt.ylabel('Normalized Sample')
plt.title('Least Mean Squares (LMS) Online Adaptation')
plt.legend(('Original', 'Prediction Error'))
plt.show()

</pre>
                <p class="mt-4">
                    Execute the program with python lmsexample.py
                    Observe: its prediction error is bigger than in the LPC case, but we also don‚Äôt need
                    to transmit the prediction coefficients as side information.
                    The comparison plot of the original to the prediction error,
                    The resulting plot can be seen in Fig. (12.17). For the decoder we get the reconstruction
                </p>

                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

# Decoder
h = np.zeros(10);
xrek = np.zeros(np.size(x));
for n in range(10, len(x)):
xrek[n] = e[n] + np.dot(np.flipud(xrek[n-10+np.arange(10)]), h)
#LMS update:
h = h + 1.0 * e[n]*np.flipud(xrek[n-10+np.arange(10)]);
plt.plot(xrek)
plt.show()
#Listen to the reconstructed signal:
sound(2**15*xrek,fs)

</pre>

                <p class="mt-4">
                    Sensitivity of the decoder for transmission errors: In the code for the decoder in
                    the LMS update for the predictor h, correctly we need xrek instead of x (since x is
                    not available in the decoder). The slightest computation errors, for instance rounding
                    errors, are sufficient to make the decoder diverge and stop working after a few syllables
                    of the speech. Try it out. We see that the computed prediction coefficients differ in
                    the last digits between encoder and decoder, which is enough for increasing divergence
                    between encoder and decoder, until the decoded signal ‚Äúexplodes‚Äù (becomes huge from
                    instability).
                    This shows that LMS is very sensitive to transmission errors.
                    To avoid at least the computation errors, we need to include quantization in the
                    process.
                </p>
                <div class="flex flex-col justify-around items-center gap-2">
                    <img src="assets/images/chap12/fig12.17.png" class="w-180 h-110 ">


                </div>
            </mat-card-content>

        </mat-card>
    </div>


    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.8 Prediction with Quantizer
                </h3>


                <p class="mt-4">
                    The block diagram of a predictive encoder with quantizer can be seen in Fig. (12.18).
                    Here we can see a predictive encoder with quantization of the prediction error. In order
                    to make sure the encoder predictor works on the quantized values, like in the decoder,
                    it uses a decoder in the encoder structure, which produces the quantized reconstructed
                    value Q(x(n))(the function Q() here include both, quantizer and de-quantizer).


                </p>
                <p class="mt-4">
                    The decoder stays the same, except for the de-quantization of the prediction error in
                    the beginning, as shown in Fig. (12.19).
                    Observe: The reconstructed signal x(n) is the same as for the encoder, plus the quantization error
                    from the quantizer:
                </p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
Q(x(n)) = e(n) + \hat{x}(n)
 $$"></p>

            </mat-card-content>

        </mat-card>
    </div>

    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.8.1 LMS with Quantizer Python Example
                </h3>


                <p class="mt-4">
                    Write a Python program file with
                </p>
                <pre class="bg-gray-100 text-sm p-3 rounded-lg overflow-x-auto font-mono mt-2">

import numpy as np
from sound import *
import matplotlib.pyplot as plt

x, fs = wavread("fspeech.wav")

# normalized float, -1 < x < 1
x = np.array(x, dtype=float) / 2**15

print(np.size(x))

e = np.zeros(np.size(x))
xrek = np.zeros(np.size(x))
P = 0
L = 10

h = np.zeros(L)

# start values same as decoder
x[0:L] = 0.0

quantstep = 0.01

for n in range(L, len(x)):

    if n > 4000 and n < 4010:
        print("encoder h:", h, "e =", e[n])

    # predicted value from past reconstructed values
    P = np.dot(np.flipud(xrek[n - L + np.arange(L)]), h)

    # quantize and dequantize prediction error
    e[n] = np.round((x[n] - P) / quantstep) * quantstep

    # decoder inside encoder: reconstructed value
    xrek[n] = e[n] + P

    # LMS update rule
    h = h + 1.0 * e[n] * np.flipud(xrek[n - L + np.arange(L)])

# error statistics
print("Mean squared prediction error:", np.dot(e, e) / np.max(np.size(e)))
print("Mean squared signal power:", np.dot(x.T, x) / np.max(np.size(x)))
print("Signal to Error ratio:", np.dot(x.T, x) / np.dot(e.T, e))

# listen to the error
sound(2**15 * e, fs)

plt.figure()
plt.plot(x)
plt.plot(e, "r")
plt.xlabel("Sample")
plt.ylabel("Normalized Sample")
plt.title("Least Mean Squares (LMS) Online Adaptation")
plt.legend(("Original", "Prediction Error"))
plt.show()

# Decoder
h = np.zeros(L)
xrek = np.zeros(np.size(x))

for n in range(L, len(x)):

    if n > 4000 and n < 4010:
        print("decoder h:", h)

    P = np.dot(np.flipud(xrek[n - L + np.arange(L)]), h)
    xrek[n] = e[n] + P

    # LMS update
    h = h + 1.0 * e[n] * np.flipud(xrek[n - L + np.arange(L)])

plt.plot(xrek)
plt.xlabel("Sample")
plt.ylabel("Normalized Sample")
plt.title("The Reconstructed Signal")
plt.show()

# listen to reconstructed signal
sound(2**15 * xrek, fs)


</pre>
                <p>
                    Execute it with
                    python lmsquantexample.py
                    Observe: Because of the quantization, the prediction error now clearly increased.
                    Observe: The signal is now fully decoded, even with quantization, although with a
                    little noise, which was to be expected. But we can avoid the noise by reducing the
                    quantization step size.
                    Observe that this structure for the decoder in the encoder also applies to the other
                    prediction methods
                </p>

                <p class="text-center mt-3 text-lg font-mono">
                    formula
                </p>
            </mat-card-content>

        </mat-card>
    </div>
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    12.9 Summary
                </h3>


                <p class="mt-4">


                    This chapter explores advanced filtering techniques for signal processing, focusing on **noise
                    reduction**, **signal detection**, and **prediction**.


                </p>

                <p class="mt-4">
                    The key components are summarized below:
                </p>

                <h2>1. Wiener Filter</h2>

                <ul>
                    <li><strong>Purpose:</strong> To approximate the original signal x(n) from a distorted signal y(n)
                        by minimizing the mean squared error.</li>

                    <li><strong>Mathematical Framework:</strong> Uses the Wiener‚ÄìHopf and Yule‚ÄìWalker equations to
                        determine optimal filter coefficients. Matrix formulations and the Moore‚ÄìPenrose pseudo-inverse
                        are used to solve the convolution problem.</li>

                    <li><strong>Applications:</strong> Noise suppression in audio, image processing, and other domains.
                    </li>
                </ul>

                <br>

                <h2>2. Matched Filter</h2>

                <ul>
                    <li><strong>Purpose:</strong> Designed to maximize the signal-to-noise ratio (SNR) for detecting
                        specific patterns or signals.</li>

                    <li><strong>Key Insight:</strong> The filter is tuned to the expected signal, making it effective
                        for deterministic signal detection.</li>

                    <li><strong>Applications:</strong> Used in communications, radar, and object recognition.</li>
                </ul>

                <br>

                <h2>3. Prediction</h2>

                <ul>
                    <li><strong>Description:</strong> A Wiener filter variant used to predict future signal samples
                        based on past samples, minimizing prediction error.</li>

                    <li><strong>Key Equations:</strong> Prediction coefficients are derived using autocorrelation and
                        cross-correlation matrices.</li>

                    <li><strong>Practical Use:</strong> Commonly applied in predictive coding, such as LPC coders in
                        speech processing.</li>
                </ul>

                <br>

                <h2>4. Python Implementations</h2>

                <ul>
                    <li><strong>Overview:</strong> Practical Python examples show Wiener filters, matched filters, and
                        predictive filtering.</li>

                    <li><strong>Applications:</strong> Include denoising noisy signals and predicting signal behavior
                        using matrix operations and numerical libraries.</li>
                </ul>

                <br>

                <h2>5. Applications of Prediction Filters</h2>

                <ul>
                    <li>Predictive coding of speech signals for low-bit-rate transmission.</li>
                    <li>Reconstruction of signals using predictive decoders to minimize error.</li>
                </ul>

                <br>

                <h2>6. Neural Network Extensions</h2>

                <ul>
                    <li>Introduces the use of Convolutional Neural Networks (CNNs) to optimize detection filters using
                        adaptive learning methods.</li>
                </ul>

            </mat-card-content>

        </mat-card>
    </div>
    <div>
        <mat-card class="example-card text-2xl" appearance="outlined">

            <mat-card-content class="text-lg">
                <h3 class="text-2xl font-semibold font-sans " style="color: blue;">
                    2.10 Homework Problems
                </h3>

                <br>

                <h3>Problem 1: Wiener Filter Design</h3>

                <p>Given a noisy signal</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
x(n) = 0.9x(n-1) + v(n)
 $$"></p>


                <p>x(n) is the original clean signal. w(n) is additive white Gaussian noise with zero mean and variance
                    sigma_w_squared.</p>

                <ol>
                    <li>Derive the Wiener filter coefficients used to estimate x(n) from y(n).</li>

                    <li>
                        Assume x(n) follows a first-order autoregressive model:
                        <pre>x(n) = 0.9 * x(n - 1) + v(n)</pre>
                        where v(n) is white noise with variance sigma_v_squared = 0.1.
                        Compute the Wiener filter coefficients.
                    </li>

                    <li>Implement the Wiener filter in Python and compare the original and estimated signals.</li>
                </ol>

                <br>

                <h3>Problem 2: Matched Filter</h3>

                <p>A deterministic signal s(t) is transmitted through a channel with additive white Gaussian noise w(t).
                </p>

                <p>The received signal is:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
r(t) = s(t) + w(t) $$"></p>


                <p>The signal s(t) is a rectangular pulse of duration T:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
s(t) = \begin{cases} 1, & 0 \leq t \leq T \\ 0, & \text{otherwise} \end{cases}) $$"></p>


                <ul>
                    <li>Derive the matched filter response for s(t).</li>
                    <li>Show that the matched filter maximizes the output signal-to-noise ratio.</li>
                    <li>Plot the matched filter output for r(t) using Python.</li>
                </ul>

                <br>

                <h3>Problem 3: Prediction Using Wiener Filter</h3>

                <p>Consider the signal model:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
x(n) = 0.8x(n-1) + v(n)
 $$"></p>


                <p>where v(n) is white Gaussian noise with variance sigma_v_squared = 0.05.</p>

                <ol>
                    <li>Design a one-step predictor to estimate x(n) from past samples.</li>
                    <li>Compute the mean squared prediction error.</li>
                    <li>Simulate the prediction process in Python and compare predicted and actual signals.</li>
                </ol>

                <br>

                <h3>Problem 4: Applications of Matched Filter</h3>

                <p>In a binary communication system, the transmitted symbols are +1 and -1. The received signal is:</p>
                <p class="text-lg font-mono mt-3 text-center" appMathJax="$$ 
r(t) = \pm s(t) + w(t)
 $$"></p>


                <p>s(t) is the pulse shape and w(t) is additive noise.</p>

                <ol>
                    <li>Explain how a matched filter is used to detect the transmitted symbols.</li>
                    <li>Derive the probability of detection error when w(t) is Gaussian.</li>
                </ol>

                <br>

                <h3>Problem 5: Neural Network Extensions</h3>

                <p>Consider using a Convolutional Neural Network (CNN) as an adaptive matched filter.</p>

                <ol>
                    <li>Describe how the CNN can be trained to detect a known signal s(t) hidden in noise.</li>
                    <li>Discuss the advantages and challenges of neural networks compared to traditional matched
                        filters.</li>
                </ol>


            </mat-card-content>

        </mat-card>
    </div>



    <!-- Test section  -->

    <div class="flex flex-col items-center p-3 gap-6">
        <h2 class="text-2xl font-sans font-semibold mb-4">üß† Test Your Knowledge</h2>

        <div *ngFor="let q of questions" class="w-full md:w-2/3">
            <mat-card class="mat-elevation-z6 p-6 font-sans">
                <mat-card-title>{{ q.text }}</mat-card-title>
                <br>

                <mat-card-content>
                    <mat-radio-group [(ngModel)]="q.selectedAnswer" [disabled]="q.isSubmitted">
                        <div *ngFor="let option of q.options" class="mb-2">
                            <mat-radio-button [value]="option">{{ option }}</mat-radio-button>
                        </div>
                    </mat-radio-group>

                    <div class="mt-4 flex gap-3">
                        <button matFab extended (click)="submitAnswer(q)"
                            [disabled]="!q.selectedAnswer || q.isSubmitted">
                            Submit
                        </button>

                        <button matFab extended style="background-color:black ; color: aliceblue;" *ngIf="q.isSubmitted"
                            (click)="tryAgain(q)">
                            Try Again
                        </button>
                    </div>

                    <div class="mt-4">
                        <p *ngIf="q.isSubmitted && q.selectedAnswer === q.correctAnswer"
                            class="text-green-600 font-semibold font-sans">
                            ‚úÖ Correct!
                        </p>
                        <p *ngIf="q.isSubmitted && q.selectedAnswer !== q.correctAnswer"
                            class="text-red-600 font-semibold font-sans">
                            ‚ùå Incorrect. Correct answer: <strong>{{ q.correctAnswer }}</strong>.
                        </p>
                    </div>
                </mat-card-content>
            </mat-card>
        </div>
    </div>



</div>